{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AIM\n<div style = \"text-align: justify\">Using U-net, localize the area which contains tumor growth <b>(which cannot be easily determined by looking at the actual medical images)</b> and compare it against the mask images. Then by looking at the generated mask image, classify whether the tumor growth is <b>malignant, benign or normal.</b> Then we must also classify the masks.</div>\n\n# Note\n<div style = \"text-align: justify\">Later in the notebook, I have mentioned images taken from medical imaging as <b>real image</b> !!!</div>\n\n# Dataset [Link](https://www.kaggle.com/aryashah2k/breast-ultrasound-images-dataset)\n\n# Please checkout the [U-net paper](https://arxiv.org/pdf/1505.04597.pdf)","metadata":{}},{"cell_type":"markdown","source":"# Import images","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:34:07.034906Z","iopub.execute_input":"2022-08-19T13:34:07.035242Z","iopub.status.idle":"2022-08-19T13:34:12.158102Z","shell.execute_reply.started":"2022-08-19T13:34:07.035162Z","shell.execute_reply":"2022-08-19T13:34:12.157263Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:39:36.591622Z","iopub.execute_input":"2022-08-19T13:39:36.591965Z","iopub.status.idle":"2022-08-19T13:39:36.596467Z","shell.execute_reply.started":"2022-08-19T13:39:36.591934Z","shell.execute_reply":"2022-08-19T13:39:36.595060Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/'","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:39:40.629797Z","iopub.execute_input":"2022-08-19T13:39:40.630139Z","iopub.status.idle":"2022-08-19T13:39:40.634621Z","shell.execute_reply.started":"2022-08-19T13:39:40.630106Z","shell.execute_reply":"2022-08-19T13:39:40.633353Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import img_to_array","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:39:42.994020Z","iopub.execute_input":"2022-08-19T13:39:42.996384Z","iopub.status.idle":"2022-08-19T13:39:43.052369Z","shell.execute_reply.started":"2022-08-19T13:39:42.996340Z","shell.execute_reply":"2022-08-19T13:39:43.051427Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Helper function** to get the index for real image and mask.","metadata":{}},{"cell_type":"code","source":"def num (image) :\n    \n    val = 0\n    \n    for i in range(len(image)) :\n        if image[i] == '(' :\n            while True :\n                i += 1\n                if image[i] == ')' :\n                    break\n                val = (val*10) + int(image[i])\n            break\n    \n    return val","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:39:45.974926Z","iopub.execute_input":"2022-08-19T13:39:45.975263Z","iopub.status.idle":"2022-08-19T13:39:45.981781Z","shell.execute_reply.started":"2022-08-19T13:39:45.975231Z","shell.execute_reply":"2022-08-19T13:39:45.980877Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<div style = \"text-align: justify\">Initialize the arrays for benign, normal and malignant tumors, both real and mask. As already given the number of samples in benign, normal & malignant are <b>437, 133 and 210</b> respectively.</div>","metadata":{}},{"cell_type":"code","source":"X_b, y_b = np.zeros((437, 128, 128, 1)), np.zeros((437, 128, 128, 1))\nX_n, y_n = np.zeros((133, 128, 128, 1)), np.zeros((133, 128, 128, 1))\nX_m, y_m = np.zeros((210, 128, 128, 1)), np.zeros((210, 128, 128, 1))","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:39:49.607866Z","iopub.execute_input":"2022-08-19T13:39:49.608190Z","iopub.status.idle":"2022-08-19T13:39:49.613527Z","shell.execute_reply.started":"2022-08-19T13:39:49.608158Z","shell.execute_reply":"2022-08-19T13:39:49.612647Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for i, tumor_type in enumerate(os.listdir(path)) :\n    for image in os.listdir(path+tumor_type+'/') :\n        p = os.path.join(path+tumor_type, image)\n        img = cv2.imread(p,cv2.IMREAD_GRAYSCALE)           # read image as  grayscale\n        \n        if image[-5] == ')' :\n            \n            img = cv2.resize(img,(128,128))\n            pil_img = Image.fromarray (img)\n            \n            if image[0] == 'b' :\n                X_b[num(image)-1]+= img_to_array(pil_img)  # If image is real add it\n            if image[0] == 'n' :                           # to X as benign , normal\n                X_n[num(image)-1]+= img_to_array(pil_img)  # or malignant.\n            if image[0] == 'm' :\n                X_m[num(image)-1]+= img_to_array(pil_img)\n        else :\n            img = cv2.resize(img,(128,128))\n            pil_img = Image.fromarray (img)\n            \n            if image[0] == 'b' :\n                y_b[num(image)-1]+= img_to_array(pil_img)  # Similarly add the target\n            if image[0] == 'n' :                           # mask to y.\n                y_n[num(image)-1]+= img_to_array(pil_img)\n            if image[0] == 'm' :\n                y_m[num(image)-1]+= img_to_array(pil_img)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:39:50.032718Z","iopub.execute_input":"2022-08-19T13:39:50.033045Z","iopub.status.idle":"2022-08-19T13:40:09.029146Z","shell.execute_reply.started":"2022-08-19T13:39:50.033012Z","shell.execute_reply":"2022-08-19T13:40:09.028123Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Visualize the results to verify the above method","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20,10))\n\nfor i in range(5) :\n    plt.subplot(2,5,i+1)\n    plt.imshow(X_b[i+1], 'gray')\n    plt.title('Real Image')\n    plt.axis('off')\n\nfor i in range(5) :\n    plt.subplot(2,5,i+6)\n    plt.imshow(y_b[i+1], 'gray')\n    plt.title('Mask Image')\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.030703Z","iopub.execute_input":"2022-08-19T13:40:09.031015Z","iopub.status.idle":"2022-08-19T13:40:09.655689Z","shell.execute_reply.started":"2022-08-19T13:40:09.030981Z","shell.execute_reply":"2022-08-19T13:40:09.654206Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Why did I take these pixelated masks instead of taking original size ?\n<div style = \"text-align: justify\">I did try to take large image sizes, <b>but due to GPU and RAM constraints</b>, my kernel kept on crashing. So I went with smaller sizes. I encourage the reader to try some different sizes where masks are more accurate.</div>","metadata":{}},{"cell_type":"markdown","source":"# Create datasets for model training and validation","metadata":{}},{"cell_type":"code","source":"X = np.concatenate((X_b, X_n, X_m), axis = 0)\ny = np.concatenate((y_b, y_n, y_m), axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.657344Z","iopub.execute_input":"2022-08-19T13:40:09.657625Z","iopub.status.idle":"2022-08-19T13:40:09.733110Z","shell.execute_reply.started":"2022-08-19T13:40:09.657594Z","shell.execute_reply":"2022-08-19T13:40:09.732237Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X /= 255.0\ny /= 255.0","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.734732Z","iopub.execute_input":"2022-08-19T13:40:09.735075Z","iopub.status.idle":"2022-08-19T13:40:09.762102Z","shell.execute_reply.started":"2022-08-19T13:40:09.735038Z","shell.execute_reply":"2022-08-19T13:40:09.761342Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.763360Z","iopub.execute_input":"2022-08-19T13:40:09.763700Z","iopub.status.idle":"2022-08-19T13:40:09.768600Z","shell.execute_reply.started":"2022-08-19T13:40:09.763664Z","shell.execute_reply":"2022-08-19T13:40:09.767691Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(X.max())\nprint(X.min())","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.769882Z","iopub.execute_input":"2022-08-19T13:40:09.770502Z","iopub.status.idle":"2022-08-19T13:40:09.798610Z","shell.execute_reply.started":"2022-08-19T13:40:09.770467Z","shell.execute_reply":"2022-08-19T13:40:09.797671Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(y.max())\nprint(y.min())","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.799765Z","iopub.execute_input":"2022-08-19T13:40:09.800071Z","iopub.status.idle":"2022-08-19T13:40:09.823399Z","shell.execute_reply.started":"2022-08-19T13:40:09.800038Z","shell.execute_reply":"2022-08-19T13:40:09.822513Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y[y > 1.0] = 1.0","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.826118Z","iopub.execute_input":"2022-08-19T13:40:09.826468Z","iopub.status.idle":"2022-08-19T13:40:09.845861Z","shell.execute_reply.started":"2022-08-19T13:40:09.826434Z","shell.execute_reply":"2022-08-19T13:40:09.845060Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(y.max())\nprint(y.min())","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.847603Z","iopub.execute_input":"2022-08-19T13:40:09.847933Z","iopub.status.idle":"2022-08-19T13:40:09.870879Z","shell.execute_reply.started":"2022-08-19T13:40:09.847900Z","shell.execute_reply":"2022-08-19T13:40:09.869904Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10,30))\ni = 0\nwhile i < 16 :\n    \n    x = np.random.randint(0,780)\n    \n    plt.subplot(8,2,i+1)\n    plt.imshow(X[x],'gray')\n    plt.title('Real Image')\n    plt.axis('off')\n    \n    plt.subplot(8,2,i+2)\n    plt.imshow(y[x],'gray')\n    plt.title('Mask Image')\n    plt.axis('off')\n    \n    i += 2\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:09.872287Z","iopub.execute_input":"2022-08-19T13:40:09.872614Z","iopub.status.idle":"2022-08-19T13:40:10.958885Z","shell.execute_reply.started":"2022-08-19T13:40:09.872578Z","shell.execute_reply":"2022-08-19T13:40:10.957918Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"<div style = \"text-align: justify\"> <b>Take a good look at image 2 and 8</b> and think if the masks were not provided, then would it have been easy to know the location tumor. NO !!! This is the aim of U-net model, localize the abnormalities in the image itself. Let's see the implementation.</div>","metadata":{}},{"cell_type":"markdown","source":"# Train test split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:10.960351Z","iopub.execute_input":"2022-08-19T13:40:10.960689Z","iopub.status.idle":"2022-08-19T13:40:11.475878Z","shell.execute_reply.started":"2022-08-19T13:40:10.960653Z","shell.execute_reply":"2022-08-19T13:40:11.474885Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:11.477188Z","iopub.execute_input":"2022-08-19T13:40:11.477536Z","iopub.status.idle":"2022-08-19T13:40:11.546729Z","shell.execute_reply.started":"2022-08-19T13:40:11.477501Z","shell.execute_reply":"2022-08-19T13:40:11.545816Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:11.548031Z","iopub.execute_input":"2022-08-19T13:40:11.548572Z","iopub.status.idle":"2022-08-19T13:40:11.553676Z","shell.execute_reply.started":"2022-08-19T13:40:11.548532Z","shell.execute_reply":"2022-08-19T13:40:11.552842Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:11.554876Z","iopub.execute_input":"2022-08-19T13:40:11.555411Z","iopub.status.idle":"2022-08-19T13:40:11.565817Z","shell.execute_reply.started":"2022-08-19T13:40:11.555376Z","shell.execute_reply":"2022-08-19T13:40:11.564966Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Model Creation [U-net](https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5)\n<img src = \"https://miro.medium.com/max/3600/1*f7YOaE4TWubwaFF7Z1fzNw.png\"/>","metadata":{}},{"cell_type":"markdown","source":"### Basic Architecture\n<div style = \"text-align: justify\">U-net architecture can localize the area of interest. It was first used in Biomedical imaging. The reason it is able to <b>distinguish and localize</b> the area is by classifying every pixel in the input image. <b>So the size of input and output images is the same</b>. It comprises of two paths - <b>Contracting path and Expanding path</b>.</div>\n\n### Contract Path\nThe Contracting path has two Convolutional layers and a Maxpooling layer.\n\n### Expansive Path\n<div style = \"text-align: justify\">The Expanding path consists of both transpose Convolutional layer and two Convolutional layers. The corresponding image from contracting path is fed to this layer for precise predictions.</div>","metadata":{}},{"cell_type":"markdown","source":"### Modifications\n<div style = \"text-align: justify\">I kept the padding same so that I can get the mask of exact same dimensions as the actual image. The adam gradient descent was used with a small <b>learning rate of 0.00005</b>. Also I am planning to add BatchNormalization which was discovered after U-net. </div>","metadata":{}},{"cell_type":"code","source":"from keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import Dropout\nfrom keras.layers import Concatenate\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Conv2DTranspose\n\nfrom keras import Model","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:11.567024Z","iopub.execute_input":"2022-08-19T13:40:11.567513Z","iopub.status.idle":"2022-08-19T13:40:11.575436Z","shell.execute_reply.started":"2022-08-19T13:40:11.567458Z","shell.execute_reply":"2022-08-19T13:40:11.574346Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Contracting path","metadata":{}},{"cell_type":"code","source":"inply = Input((128, 128, 1,))\n\nconv1 = Conv2D(2**6, (3,3), activation = 'relu', padding = 'same')(inply)\nconv1 = Conv2D(2**6, (3,3), activation = 'relu', padding = 'same')(conv1)\npool1 = MaxPooling2D((2,2), strides = 2, padding = 'same')(conv1)\ndrop1 = Dropout(0.2)(pool1)\n\nconv2 = Conv2D(2**7, (3,3), activation = 'relu', padding = 'same')(drop1)\nconv2 = Conv2D(2**7, (3,3), activation = 'relu', padding = 'same')(conv2)\npool2 = MaxPooling2D((2,2), strides = 2, padding = 'same')(conv2)\ndrop2 = Dropout(0.2)(pool2)\n\nconv3 = Conv2D(2**8, (3,3), activation = 'relu', padding = 'same')(drop2)\nconv3 = Conv2D(2**8, (3,3), activation = 'relu', padding = 'same')(conv3)\npool3 = MaxPooling2D((2,2), strides = 2, padding = 'same')(conv3)\ndrop3 = Dropout(0.2)(pool3)\n\nconv4 = Conv2D(2**9, (3,3), activation = 'relu', padding = 'same')(drop3)\nconv4 = Conv2D(2**9, (3,3), activation = 'relu', padding = 'same')(conv4)\npool4 = MaxPooling2D((2,2), strides = 2, padding = 'same')(conv4)\ndrop4 = Dropout(0.2)(pool4)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:11.576615Z","iopub.execute_input":"2022-08-19T13:40:11.576854Z","iopub.status.idle":"2022-08-19T13:40:13.913523Z","shell.execute_reply.started":"2022-08-19T13:40:11.576831Z","shell.execute_reply":"2022-08-19T13:40:13.912599Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Bottleneck layer","metadata":{}},{"cell_type":"code","source":"convm = Conv2D(2**10, (3,3), activation = 'relu', padding = 'same')(drop4)\nconvm = Conv2D(2**10, (3,3), activation = 'relu', padding = 'same')(convm)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:13.914913Z","iopub.execute_input":"2022-08-19T13:40:13.915307Z","iopub.status.idle":"2022-08-19T13:40:13.937570Z","shell.execute_reply.started":"2022-08-19T13:40:13.915243Z","shell.execute_reply":"2022-08-19T13:40:13.936820Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Expanding layer","metadata":{}},{"cell_type":"code","source":"tran5 = Conv2DTranspose(2**9, (2,2), strides = 2, padding = 'valid', activation = 'relu')(convm)\nconc5 = Concatenate()([tran5, conv4])\nconv5 = Conv2D(2**9, (3,3), activation = 'relu', padding = 'same')(conc5)\nconv5 = Conv2D(2**9, (3,3), activation = 'relu', padding = 'same')(conv5)\ndrop5 = Dropout(0.1)(conv5)\n\ntran6 = Conv2DTranspose(2**8, (2,2), strides = 2, padding = 'valid', activation = 'relu')(drop5)\nconc6 = Concatenate()([tran6, conv3])\nconv6 = Conv2D(2**8, (3,3), activation = 'relu', padding = 'same')(conc6)\nconv6 = Conv2D(2**8, (3,3), activation = 'relu', padding = 'same')(conv6)\ndrop6 = Dropout(0.1)(conv6)\n\ntran7 = Conv2DTranspose(2**7, (2,2), strides = 2, padding = 'valid', activation = 'relu')(drop6)\nconc7 = Concatenate()([tran7, conv2])\nconv7 = Conv2D(2**7, (3,3), activation = 'relu', padding = 'same')(conc7)\nconv7 = Conv2D(2**7, (3,3), activation = 'relu', padding = 'same')(conv7)\ndrop7 = Dropout(0.1)(conv7)\n\ntran8 = Conv2DTranspose(2**6, (2,2), strides = 2, padding = 'valid', activation = 'relu')(drop7)\nconc8 = Concatenate()([tran8, conv1])\nconv8 = Conv2D(2**6, (3,3), activation = 'relu', padding = 'same')(conc8)\nconv8 = Conv2D(2**6, (3,3), activation = 'relu', padding = 'same')(conv8)\ndrop8 = Dropout(0.1)(conv8)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:13.938839Z","iopub.execute_input":"2022-08-19T13:40:13.939158Z","iopub.status.idle":"2022-08-19T13:40:14.073998Z","shell.execute_reply.started":"2022-08-19T13:40:13.939125Z","shell.execute_reply":"2022-08-19T13:40:14.073178Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"outly = Conv2D(2**0, (1,1), activation = 'relu', padding = 'same')(drop8)\nmodel = Model(inputs = inply, outputs = outly, name = 'U-net')","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:14.075369Z","iopub.execute_input":"2022-08-19T13:40:14.075726Z","iopub.status.idle":"2022-08-19T13:40:14.095697Z","shell.execute_reply.started":"2022-08-19T13:40:14.075692Z","shell.execute_reply":"2022-08-19T13:40:14.094839Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model, './model_plot.png', show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:14.096767Z","iopub.execute_input":"2022-08-19T13:40:14.097121Z","iopub.status.idle":"2022-08-19T13:40:14.980527Z","shell.execute_reply.started":"2022-08-19T13:40:14.097088Z","shell.execute_reply":"2022-08-19T13:40:14.974946Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Loss function\n\n<div style = \"text-align: justify\">The loss for evaluating the performance of model in semantic segmentation will be <b>IoU (Intersection over Union)</b>. It is the ratio of intersection of pixels between predicted and target image over their union. The MeanIoU() method in tf.keras.metrics package can be used.</div>","metadata":{}},{"cell_type":"code","source":"from keras.metrics import MeanIoU","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:14.983366Z","iopub.execute_input":"2022-08-19T13:40:14.983909Z","iopub.status.idle":"2022-08-19T13:40:14.988529Z","shell.execute_reply.started":"2022-08-19T13:40:14.983870Z","shell.execute_reply":"2022-08-19T13:40:14.987580Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model.compile(loss = 'mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.00005))\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:19.940135Z","iopub.execute_input":"2022-08-19T13:40:19.940510Z","iopub.status.idle":"2022-08-19T13:40:19.980684Z","shell.execute_reply.started":"2022-08-19T13:40:19.940477Z","shell.execute_reply":"2022-08-19T13:40:19.979776Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:21.759912Z","iopub.execute_input":"2022-08-19T13:40:21.760242Z","iopub.status.idle":"2022-08-19T13:40:21.765299Z","shell.execute_reply.started":"2022-08-19T13:40:21.760209Z","shell.execute_reply":"2022-08-19T13:40:21.764265Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"checkp = ModelCheckpoint('./cancer_image_model.h5', monitor = 'val_loss', save_best_only = True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:23.270826Z","iopub.execute_input":"2022-08-19T13:40:23.271162Z","iopub.status.idle":"2022-08-19T13:40:23.277849Z","shell.execute_reply.started":"2022-08-19T13:40:23.271128Z","shell.execute_reply":"2022-08-19T13:40:23.276995Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs = 100, batch_size = 32, validation_data = (X_test, y_test), callbacks = [checkp])","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:40:23.863112Z","iopub.execute_input":"2022-08-19T13:40:23.863579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Performance","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20,7))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training loss', 'validation loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.title('Losses vs Epochs', fontsize = 15)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:18:15.141347Z","iopub.execute_input":"2021-06-23T15:18:15.141683Z","iopub.status.idle":"2021-06-23T15:18:15.329121Z","shell.execute_reply.started":"2021-06-23T15:18:15.141649Z","shell.execute_reply":"2021-06-23T15:18:15.328207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('./cancer_image_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:18:15.524016Z","iopub.execute_input":"2021-06-23T15:18:15.524342Z","iopub.status.idle":"2021-06-23T15:18:16.38776Z","shell.execute_reply.started":"2021-06-23T15:18:15.524311Z","shell.execute_reply":"2021-06-23T15:18:16.386868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:18:18.016474Z","iopub.execute_input":"2021-06-23T15:18:18.016833Z","iopub.status.idle":"2021-06-23T15:18:21.44095Z","shell.execute_reply.started":"2021-06-23T15:18:18.0168Z","shell.execute_reply":"2021-06-23T15:18:21.440087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_pred.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:18:21.443092Z","iopub.execute_input":"2021-06-23T15:18:21.443698Z","iopub.status.idle":"2021-06-23T15:18:21.448717Z","shell.execute_reply.started":"2021-06-23T15:18:21.443659Z","shell.execute_reply":"2021-06-23T15:18:21.447639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20,80))\n\ni = 0\nx = 0\nwhile i < 45 :\n    \n    plt.subplot(15,3,i+1)\n    plt.imshow(X_test[x], 'gray')\n    plt.title('Real medic Image')\n    plt.axis('off')\n    \n    plt.subplot(15,3,i+2)\n    plt.imshow(y_test[x], 'gray')\n    plt.title('Ground Truth Img')\n    plt.axis('off')\n    \n    plt.subplot(15,3,i+3)\n    plt.imshow(y_pred[x], 'gray')\n    plt.title('Predicited Image')\n    plt.axis('off')\n    \n    x += 1\n    i += 3\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:18:23.488357Z","iopub.execute_input":"2021-06-23T15:18:23.488683Z","iopub.status.idle":"2021-06-23T15:18:26.79252Z","shell.execute_reply.started":"2021-06-23T15:18:23.488648Z","shell.execute_reply":"2021-06-23T15:18:26.791749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classifier","metadata":{}},{"cell_type":"code","source":"info = [\n    'benign'   ,  # 0\n    'normal'   ,  # 1\n    'malignant',  # 2\n]","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:44.673135Z","iopub.execute_input":"2021-06-23T15:19:44.673477Z","iopub.status.idle":"2021-06-23T15:19:44.679743Z","shell.execute_reply.started":"2021-06-23T15:19:44.673447Z","shell.execute_reply":"2021-06-23T15:19:44.678851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/'","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:44.920027Z","iopub.execute_input":"2021-06-23T15:19:44.920353Z","iopub.status.idle":"2021-06-23T15:19:44.924289Z","shell.execute_reply.started":"2021-06-23T15:19:44.920323Z","shell.execute_reply":"2021-06-23T15:19:44.923203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []\ny = []\n\nlabel_num = -1\n\nfor label_class in os.listdir(path) :\n    \n    new_path   = path + label_class\n    label_num += 1\n    \n    for img in os.listdir(new_path) :\n        if 'mask' not in img :\n            \n            y.append(label_num)\n            x = cv2.imread(path + label_class +'/'+img, cv2.IMREAD_GRAYSCALE)\n            X.append(img_to_array(Image.fromarray(cv2.resize(x, (128,128)))))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:45.17599Z","iopub.execute_input":"2021-06-23T15:19:45.176321Z","iopub.status.idle":"2021-06-23T15:19:53.220685Z","shell.execute_reply.started":"2021-06-23T15:19:45.176293Z","shell.execute_reply":"2021-06-23T15:19:53.219847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:53.222087Z","iopub.execute_input":"2021-06-23T15:19:53.222412Z","iopub.status.idle":"2021-06-23T15:19:53.242825Z","shell.execute_reply.started":"2021-06-23T15:19:53.222379Z","shell.execute_reply":"2021-06-23T15:19:53.241972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X/= 255.0","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:53.244746Z","iopub.execute_input":"2021-06-23T15:19:53.24513Z","iopub.status.idle":"2021-06-23T15:19:53.254199Z","shell.execute_reply.started":"2021-06-23T15:19:53.245094Z","shell.execute_reply":"2021-06-23T15:19:53.253456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:53.256175Z","iopub.execute_input":"2021-06-23T15:19:53.256607Z","iopub.status.idle":"2021-06-23T15:19:53.260506Z","shell.execute_reply.started":"2021-06-23T15:19:53.256572Z","shell.execute_reply":"2021-06-23T15:19:53.25958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:53.262031Z","iopub.execute_input":"2021-06-23T15:19:53.26264Z","iopub.status.idle":"2021-06-23T15:19:53.269102Z","shell.execute_reply.started":"2021-06-23T15:19:53.262604Z","shell.execute_reply":"2021-06-23T15:19:53.268275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:53.269995Z","iopub.execute_input":"2021-06-23T15:19:53.272184Z","iopub.status.idle":"2021-06-23T15:19:53.280484Z","shell.execute_reply.started":"2021-06-23T15:19:53.272147Z","shell.execute_reply":"2021-06-23T15:19:53.279473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.min())\nprint(X.max())","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:53.282117Z","iopub.execute_input":"2021-06-23T15:19:53.282483Z","iopub.status.idle":"2021-06-23T15:19:53.298027Z","shell.execute_reply.started":"2021-06-23T15:19:53.282448Z","shell.execute_reply":"2021-06-23T15:19:53.297119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X[0], 'gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:53.300268Z","iopub.execute_input":"2021-06-23T15:19:53.300614Z","iopub.status.idle":"2021-06-23T15:19:53.386588Z","shell.execute_reply.started":"2021-06-23T15:19:53.30058Z","shell.execute_reply":"2021-06-23T15:19:53.385774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:53.387984Z","iopub.execute_input":"2021-06-23T15:19:53.388476Z","iopub.status.idle":"2021-06-23T15:19:53.392538Z","shell.execute_reply.started":"2021-06-23T15:19:53.388439Z","shell.execute_reply":"2021-06-23T15:19:53.391741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"localize = load_model('./cancer_image_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:54.008314Z","iopub.execute_input":"2021-06-23T15:19:54.008627Z","iopub.status.idle":"2021-06-23T15:19:54.882591Z","shell.execute_reply.started":"2021-06-23T15:19:54.008599Z","shell.execute_reply":"2021-06-23T15:19:54.881713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"M = localize.predict(X)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:19:54.884214Z","iopub.execute_input":"2021-06-23T15:19:54.884546Z","iopub.status.idle":"2021-06-23T15:21:03.113968Z","shell.execute_reply.started":"2021-06-23T15:19:54.884512Z","shell.execute_reply":"2021-06-23T15:21:03.113033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(M.min())\nprint(M.max())\n\nplt.imshow(M[0], 'gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:21:03.115678Z","iopub.execute_input":"2021-06-23T15:21:03.115999Z","iopub.status.idle":"2021-06-23T15:21:03.195469Z","shell.execute_reply.started":"2021-06-23T15:21:03.115966Z","shell.execute_reply":"2021-06-23T15:21:03.194522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data distribution","metadata":{}},{"cell_type":"code","source":"import pandas\nimport seaborn","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:21:17.516514Z","iopub.execute_input":"2021-06-23T15:21:17.516844Z","iopub.status.idle":"2021-06-23T15:21:17.581195Z","shell.execute_reply.started":"2021-06-23T15:21:17.516813Z","shell.execute_reply":"2021-06-23T15:21:17.580389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seaborn.histplot(data = pandas.DataFrame({'id' : [info[p] for p in np.argmax(y, axis = 1)]}), x = 'id')\nplt.title('Distribution of classes accross the entire dataset', fontsize = 15)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:21:17.582581Z","iopub.execute_input":"2021-06-23T15:21:17.582926Z","iopub.status.idle":"2021-06-23T15:21:17.740652Z","shell.execute_reply.started":"2021-06-23T15:21:17.582891Z","shell.execute_reply":"2021-06-23T15:21:17.739895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style = \"text-align: justify\">Although this is a imbalanced distribution, a model can easily be developed that does well in classification task. This is beause these images have clear distinctions among them.</div>","metadata":{}},{"cell_type":"markdown","source":"# train-test split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(M, y, test_size = 0.1, shuffle = True, random_state = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:21:20.984636Z","iopub.execute_input":"2021-06-23T15:21:20.984976Z","iopub.status.idle":"2021-06-23T15:21:21.007311Z","shell.execute_reply.started":"2021-06-23T15:21:20.984945Z","shell.execute_reply":"2021-06-23T15:21:21.006451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:21:26.808986Z","iopub.execute_input":"2021-06-23T15:21:26.809412Z","iopub.status.idle":"2021-06-23T15:21:26.814468Z","shell.execute_reply.started":"2021-06-23T15:21:26.809378Z","shell.execute_reply":"2021-06-23T15:21:26.813361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:21:26.832311Z","iopub.execute_input":"2021-06-23T15:21:26.832554Z","iopub.status.idle":"2021-06-23T15:21:26.837254Z","shell.execute_reply.started":"2021-06-23T15:21:26.832529Z","shell.execute_reply":"2021-06-23T15:21:26.836145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy.random import randint","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:21:26.83891Z","iopub.execute_input":"2021-06-23T15:21:26.839434Z","iopub.status.idle":"2021-06-23T15:21:26.845184Z","shell.execute_reply.started":"2021-06-23T15:21:26.839398Z","shell.execute_reply":"2021-06-23T15:21:26.844115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20,20))\ni = 0\nSIZE = 702\nwhile i < 25 :\n    \n    x = randint(0, SIZE)\n    plt.subplot(5,5,i+1)\n    plt.imshow(X_train[x], 'gray')\n    plt.title(f'{info[np.argmax(y_train[x])]}', fontsize = 15)\n    plt.axis('off')\n    \n    i += 1\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:21:26.847262Z","iopub.execute_input":"2021-06-23T15:21:26.847658Z","iopub.status.idle":"2021-06-23T15:21:28.392428Z","shell.execute_reply.started":"2021-06-23T15:21:26.847621Z","shell.execute_reply":"2021-06-23T15:21:28.391382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data augmentation","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:01.601423Z","iopub.execute_input":"2021-06-23T15:22:01.601763Z","iopub.status.idle":"2021-06-23T15:22:01.605602Z","shell.execute_reply.started":"2021-06-23T15:22:01.601732Z","shell.execute_reply":"2021-06-23T15:22:01.604506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = ImageDataGenerator(horizontal_flip = True, rotation_range = 15, width_shift_range = [-10, 10], height_shift_range = [-10, 10], zoom_range = [0.80, 1.00])","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:01.876349Z","iopub.execute_input":"2021-06-23T15:22:01.876647Z","iopub.status.idle":"2021-06-23T15:22:01.881839Z","shell.execute_reply.started":"2021-06-23T15:22:01.87662Z","shell.execute_reply":"2021-06-23T15:22:01.881003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:02.164415Z","iopub.execute_input":"2021-06-23T15:22:02.164726Z","iopub.status.idle":"2021-06-23T15:22:02.188267Z","shell.execute_reply.started":"2021-06-23T15:22:02.164697Z","shell.execute_reply":"2021-06-23T15:22:02.187427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pointer = train_gen.flow(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:02.347982Z","iopub.execute_input":"2021-06-23T15:22:02.348387Z","iopub.status.idle":"2021-06-23T15:22:02.353621Z","shell.execute_reply.started":"2021-06-23T15:22:02.348354Z","shell.execute_reply":"2021-06-23T15:22:02.352773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX, trainy = pointer.next()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:02.480172Z","iopub.execute_input":"2021-06-23T15:22:02.480434Z","iopub.status.idle":"2021-06-23T15:22:02.520571Z","shell.execute_reply.started":"2021-06-23T15:22:02.480409Z","shell.execute_reply":"2021-06-23T15:22:02.519795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20,20))\n\ni = 0\n\nwhile i < 25 :\n    \n    plt.subplot(5, 5, i+1)\n    plt.imshow(trainX[i], 'gray')\n    plt.title(f'{info[np.argmax(trainy[i])]}', fontsize = 15)\n    plt.axis('off')\n    \n    i += 1\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:02.752247Z","iopub.execute_input":"2021-06-23T15:22:02.752515Z","iopub.status.idle":"2021-06-23T15:22:04.032846Z","shell.execute_reply.started":"2021-06-23T15:22:02.752489Z","shell.execute_reply":"2021-06-23T15:22:04.032059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# make CNN model","metadata":{}},{"cell_type":"code","source":"from keras.layers import BatchNormalization\nfrom keras.models import Sequential\nfrom keras.layers import LeakyReLU\nfrom keras.optimizers import Adam\nfrom keras.layers import Flatten\nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:04.284452Z","iopub.execute_input":"2021-06-23T15:22:04.284752Z","iopub.status.idle":"2021-06-23T15:22:04.290006Z","shell.execute_reply.started":"2021-06-23T15:22:04.284721Z","shell.execute_reply":"2021-06-23T15:22:04.289134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_block (filterx) :\n    \n    model = Sequential()\n    \n    model.add(Conv2D(filterx, (3,3), strides = 1, padding = 'same', kernel_regularizer = 'l2'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.2))\n    model.add(LeakyReLU())\n    \n    model.add(MaxPooling2D())\n    \n    return model\n\ndef dens_block (hiddenx) :\n    \n    model = Sequential()\n    \n    model.add(Dense(hiddenx, kernel_regularizer = 'l2'))\n    model.add(BatchNormalization())\n    model.add(Dropout(.2))\n    model.add(LeakyReLU())\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:04.300004Z","iopub.execute_input":"2021-06-23T15:22:04.300277Z","iopub.status.idle":"2021-06-23T15:22:04.306737Z","shell.execute_reply.started":"2021-06-23T15:22:04.300253Z","shell.execute_reply":"2021-06-23T15:22:04.30577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cnn (filter1, filter2, filter3, filter4, hidden1) :\n    \n    model = Sequential([\n        \n        Input((128,128,1,)),\n        conv_block(filter1),\n        conv_block(filter2),\n        conv_block(filter3),\n        conv_block(filter4),\n        Flatten(),\n        dens_block(hidden1),\n        Dense(3, activation = 'softmax')\n    ])\n    \n    model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.0005), metrics = ['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:06.0007Z","iopub.execute_input":"2021-06-23T15:22:06.001029Z","iopub.status.idle":"2021-06-23T15:22:06.006685Z","shell.execute_reply.started":"2021-06-23T15:22:06.000998Z","shell.execute_reply":"2021-06-23T15:22:06.00555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = cnn(32, 64, 128, 256, 32)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:06.011359Z","iopub.execute_input":"2021-06-23T15:22:06.011613Z","iopub.status.idle":"2021-06-23T15:22:06.215552Z","shell.execute_reply.started":"2021-06-23T15:22:06.011588Z","shell.execute_reply":"2021-06-23T15:22:06.214754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:06.217006Z","iopub.execute_input":"2021-06-23T15:22:06.217361Z","iopub.status.idle":"2021-06-23T15:22:06.223191Z","shell.execute_reply.started":"2021-06-23T15:22:06.217327Z","shell.execute_reply":"2021-06-23T15:22:06.222338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, 'cancer_classify.png', show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:06.419825Z","iopub.execute_input":"2021-06-23T15:22:06.420097Z","iopub.status.idle":"2021-06-23T15:22:06.626575Z","shell.execute_reply.started":"2021-06-23T15:22:06.420073Z","shell.execute_reply":"2021-06-23T15:22:06.625682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# fit()","metadata":{}},{"cell_type":"code","source":"checkp = ModelCheckpoint('./valid_classifier.h5', monitor = 'val_loss', save_best_only = True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:12.777903Z","iopub.execute_input":"2021-06-23T15:22:12.778282Z","iopub.status.idle":"2021-06-23T15:22:12.783196Z","shell.execute_reply.started":"2021-06-23T15:22:12.778247Z","shell.execute_reply":"2021-06-23T15:22:12.782157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_gen.flow(X_train, y_train, batch_size = 64), epochs = 400, validation_data = (X_test, y_test), callbacks = [checkp])","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:22:14.156547Z","iopub.execute_input":"2021-06-23T15:22:14.156917Z","iopub.status.idle":"2021-06-23T15:29:12.112836Z","shell.execute_reply.started":"2021-06-23T15:22:14.156882Z","shell.execute_reply":"2021-06-23T15:29:12.112053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training_loss', 'validation_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.title('Loss val wrt. Epochs', fontsize = 15)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-06-23T15:30:57.46162Z","iopub.execute_input":"2021-06-23T15:30:57.461975Z","iopub.status.idle":"2021-06-23T15:30:57.637262Z","shell.execute_reply.started":"2021-06-23T15:30:57.461944Z","shell.execute_reply":"2021-06-23T15:30:57.636284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:06.541609Z","iopub.execute_input":"2021-06-23T15:31:06.541927Z","iopub.status.idle":"2021-06-23T15:31:06.545904Z","shell.execute_reply.started":"2021-06-23T15:31:06.541896Z","shell.execute_reply":"2021-06-23T15:31:06.544918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('./valid_classifier.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:06.965945Z","iopub.execute_input":"2021-06-23T15:31:06.966303Z","iopub.status.idle":"2021-06-23T15:31:07.249703Z","shell.execute_reply.started":"2021-06-23T15:31:06.966271Z","shell.execute_reply":"2021-06-23T15:31:07.248868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:07.997258Z","iopub.execute_input":"2021-06-23T15:31:07.997572Z","iopub.status.idle":"2021-06-23T15:31:08.142372Z","shell.execute_reply.started":"2021-06-23T15:31:07.997543Z","shell.execute_reply":"2021-06-23T15:31:08.141611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(y_pred, axis = 1)\ny_test = np.argmax(y_test, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:08.88944Z","iopub.execute_input":"2021-06-23T15:31:08.889764Z","iopub.status.idle":"2021-06-23T15:31:08.894279Z","shell.execute_reply.started":"2021-06-23T15:31:08.889732Z","shell.execute_reply":"2021-06-23T15:31:08.893235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy : ' + str(accuracy_score(y_test, y_pred)))\nprint(classification_report(y_test, y_pred, target_names = info))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:09.525169Z","iopub.execute_input":"2021-06-23T15:31:09.52549Z","iopub.status.idle":"2021-06-23T15:31:09.538456Z","shell.execute_reply.started":"2021-06-23T15:31:09.525463Z","shell.execute_reply":"2021-06-23T15:31:09.537368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion matrix","metadata":{}},{"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:13.33538Z","iopub.execute_input":"2021-06-23T15:31:13.335695Z","iopub.status.idle":"2021-06-23T15:31:13.342148Z","shell.execute_reply.started":"2021-06-23T15:31:13.335665Z","shell.execute_reply":"2021-06-23T15:31:13.341021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,12))\nax = seaborn.heatmap(cm, cmap=plt.cm.Greens, annot=True, square=True, xticklabels = info, yticklabels = info)\nax.set_ylabel('Actual', fontsize=40)\nax.set_xlabel('Predicted', fontsize=40)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:13.721364Z","iopub.execute_input":"2021-06-23T15:31:13.721682Z","iopub.status.idle":"2021-06-23T15:31:14.293347Z","shell.execute_reply.started":"2021-06-23T15:31:13.721652Z","shell.execute_reply":"2021-06-23T15:31:14.292354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overall task\n<div style = \"text-align: justify\">Now that the models are complete, we first get the mask for input image and then classify the tumor type <b>benign, malignant or normal</b> based on mask shape.</div>","metadata":{}},{"cell_type":"code","source":"image_path = [\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (110).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (101).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (107).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal/normal (101).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal/normal (111).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal/normal (106).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant/malignant (115).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant/malignant (111).png',\n    '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant/malignant (110).png',\n]","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:20.237448Z","iopub.execute_input":"2021-06-23T15:31:20.237771Z","iopub.status.idle":"2021-06-23T15:31:20.241992Z","shell.execute_reply.started":"2021-06-23T15:31:20.23774Z","shell.execute_reply":"2021-06-23T15:31:20.240921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:31:20.969101Z","iopub.execute_input":"2021-06-23T15:31:20.969456Z","iopub.status.idle":"2021-06-23T15:31:20.973543Z","shell.execute_reply.started":"2021-06-23T15:31:20.969425Z","shell.execute_reply":"2021-06-23T15:31:20.972592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load models","metadata":{}},{"cell_type":"code","source":"classifier = load_model('./valid_classifier.h5')\nlocalize = load_model('./cancer_image_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:11.813509Z","iopub.execute_input":"2021-06-23T15:33:11.813831Z","iopub.status.idle":"2021-06-23T15:33:12.861408Z","shell.execute_reply.started":"2021-06-23T15:33:11.813799Z","shell.execute_reply":"2021-06-23T15:33:12.860421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load images","metadata":{}},{"cell_type":"code","source":"testX = []\nfor img in image_path :\n    testX.append(img_to_array(Image.fromarray(cv2.resize(cv2.imread(img, cv2.IMREAD_GRAYSCALE), (128,128)))))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:12.862979Z","iopub.execute_input":"2021-06-23T15:33:12.863397Z","iopub.status.idle":"2021-06-23T15:33:12.969511Z","shell.execute_reply.started":"2021-06-23T15:33:12.863359Z","shell.execute_reply":"2021-06-23T15:33:12.968706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testX = np.array(testX)\ntestX/= 255.0","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:13.857476Z","iopub.execute_input":"2021-06-23T15:33:13.857809Z","iopub.status.idle":"2021-06-23T15:33:13.862934Z","shell.execute_reply.started":"2021-06-23T15:33:13.857775Z","shell.execute_reply":"2021-06-23T15:33:13.861783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(testX.shape)\nprint(f'Minimum : {testX.min()}')\nprint(f'Maximum : {testX.max()}')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:14.40959Z","iopub.execute_input":"2021-06-23T15:33:14.409915Z","iopub.status.idle":"2021-06-23T15:33:14.417262Z","shell.execute_reply.started":"2021-06-23T15:33:14.409887Z","shell.execute_reply":"2021-06-23T15:33:14.416213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(testX[0], 'gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:15.061631Z","iopub.execute_input":"2021-06-23T15:33:15.061989Z","iopub.status.idle":"2021-06-23T15:33:15.163595Z","shell.execute_reply.started":"2021-06-23T15:33:15.061956Z","shell.execute_reply":"2021-06-23T15:33:15.162531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# predict mask and label","metadata":{}},{"cell_type":"code","source":"predY = localize.predict(testX)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:16.29352Z","iopub.execute_input":"2021-06-23T15:33:16.293838Z","iopub.status.idle":"2021-06-23T15:33:17.366009Z","shell.execute_reply.started":"2021-06-23T15:33:16.29381Z","shell.execute_reply":"2021-06-23T15:33:17.365137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predY.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:17.697642Z","iopub.execute_input":"2021-06-23T15:33:17.69796Z","iopub.status.idle":"2021-06-23T15:33:17.703506Z","shell.execute_reply.started":"2021-06-23T15:33:17.697929Z","shell.execute_reply":"2021-06-23T15:33:17.70166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(predY[0], 'gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:17.757025Z","iopub.execute_input":"2021-06-23T15:33:17.757336Z","iopub.status.idle":"2021-06-23T15:33:17.830502Z","shell.execute_reply.started":"2021-06-23T15:33:17.757311Z","shell.execute_reply":"2021-06-23T15:33:17.829683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predY.min())\nprint(predY.max())","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:20.105923Z","iopub.execute_input":"2021-06-23T15:33:20.106285Z","iopub.status.idle":"2021-06-23T15:33:20.111701Z","shell.execute_reply.started":"2021-06-23T15:33:20.106253Z","shell.execute_reply":"2021-06-23T15:33:20.110761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_label = classifier.predict(predY)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:21.085728Z","iopub.execute_input":"2021-06-23T15:33:21.086036Z","iopub.status.idle":"2021-06-23T15:33:21.22408Z","shell.execute_reply.started":"2021-06-23T15:33:21.086007Z","shell.execute_reply":"2021-06-23T15:33:21.223187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.argmax(pred_label, axis = 1))\nplt.figure(figsize = (10,40))\n\ni = 0\nj = 0\nwhile i < 20 :\n    \n    plt.subplot(10,2,i+1)\n    plt.imshow (testX[j], 'gray')\n    plt.title('Original Image', fontsize = 15)\n    plt.axis('off')\n    \n    plt.subplot(10,2,i+2)\n    plt.imshow (predY[j], 'gray')\n    plt.title(f'{info[np.argmax(pred_label[j])]}', fontsize = 15)\n    plt.axis('off')\n    \n    j += 1\n    i += 2\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:33:22.345638Z","iopub.execute_input":"2021-06-23T15:33:22.345976Z","iopub.status.idle":"2021-06-23T15:33:23.497651Z","shell.execute_reply.started":"2021-06-23T15:33:22.345944Z","shell.execute_reply":"2021-06-23T15:33:23.496816Z"},"trusted":true},"execution_count":null,"outputs":[]}]}